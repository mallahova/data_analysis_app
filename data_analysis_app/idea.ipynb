{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.facade import DataAnalysisFacade\n",
    "facade = DataAnalysisFacade()\n",
    "data_file = \"../samples/diamonds.csv\" \n",
    "\n",
    "if data_file:  \n",
    "    data = facade.load_data(data_file)\n",
    "    preview_data = data.iloc[:100, :100]\n",
    "    facade.preprocess_data(handle_nulls={\"method\": \"mean\"}, rename_map={\"cut\": \"cut_quality\"}, drop_cols=[\"table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_analysis_app/samples/diamonds.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_analysis_app/samples/diamonds.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_latest/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_latest/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_latest/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_latest/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_latest/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_analysis_app/samples/diamonds.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"data_analysis_app/samples/diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mallahova/code/basics/projects/uj/data_analysis_app/data_analysis_app'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- App steps:\n",
    "\n",
    "7. State Pattern (for Different UI States)\n",
    "\n",
    "class AppState(ABC):\n",
    "    @abstractmethod\n",
    "    def handle(self):\n",
    "        pass\n",
    "\n",
    "class DataUploadedState(AppState):\n",
    "    def handle(self):\n",
    "        st.write(\"Data has been uploaded\")\n",
    "\n",
    "class PreprocessingState(AppState):\n",
    "    def handle(self):\n",
    "        st.write(\"Preprocessing data\")  \n",
    "\n",
    "class VisualizationState(AppState):\n",
    "    def handle(self):\n",
    "        st.write(\"Visualizing data\")\n",
    "\n",
    "class App:\n",
    "    def __init__(self):\n",
    "        self.state = DataUploadedState()\n",
    "\n",
    "    def set_state(self, state: AppState):\n",
    "        self.state = state\n",
    "\n",
    "    def handle(self):\n",
    "        self.state.handle() -->\n",
    "template for PCA/UMAP, for plotting?\n",
    "singleton for dashboard?\n",
    "singleton for client\n",
    "# mymodule.py\n",
    "class SingletonClass:\n",
    "    def __init__(self):\n",
    "        self.value = 42\n",
    "\n",
    "singleton_instance = SingletonClass()\n",
    "\n",
    "# Access this instance from other parts of your program\n",
    "# import mymodule\n",
    "# mymodule.singleton_instance\n",
    "\n",
    "composite for different plots stored in dashboard - lineplots, barplots, etc\n",
    "iterator for dashboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great choice! Building a Data Analysis Tool is an excellent project that allows you to apply several design patterns and utilize your knowledge of Python, Pandas, and Matplotlib. Below is a detailed implementation plan, including components, design patterns, and steps to build the tool.\n",
    "\n",
    "Project Overview\n",
    "The Data Analysis Tool will enable users to:\n",
    "\n",
    "Upload datasets in various formats (CSV, JSON).\n",
    "Perform basic data analysis (e.g., summary statistics, correlations).\n",
    "Visualize data using different types of plots (e.g., bar charts, scatter plots).\n",
    "Combine multiple analyses and visualizations into a single view.\n",
    "Technology Stack\n",
    "Python: Programming language\n",
    "Flask: Web framework for the web interface\n",
    "Pandas: For data manipulation and analysis\n",
    "Matplotlib/Seaborn: For data visualization\n",
    "HTML/CSS: For front-end design\n",
    "JavaScript (optional): For enhanced interactivity in the UI\n",
    "Detailed Implementation Steps\n",
    "1. Set Up the Environment\n",
    "Create a virtual environment and install required packages:\n",
    "bash\n",
    "Copy code\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n",
    "pip install Flask pandas matplotlib seaborn\n",
    "2. Define the Project Structure\n",
    "Create the following directory structure:\n",
    "\n",
    "graphql\n",
    "Copy code\n",
    "data_analysis_tool/\n",
    "│\n",
    "├── app.py                 # Main application file\n",
    "├── templates/             # HTML templates for Flask\n",
    "│   ├── upload.html        # Page for file upload\n",
    "│   ├── analysis.html      # Page to display results\n",
    "│   └── base.html          # Base template for inheritance\n",
    "├── static/                # Static files (CSS, JS)\n",
    "│   └── styles.css         # Custom styles (optional)\n",
    "├── data/                  # Directory for uploaded datasets (if needed)\n",
    "└── analysis/              # Directory for analysis classes and strategies\n",
    "    ├── __init__.py\n",
    "    ├── analysis_builder.py # For the Builder pattern\n",
    "    ├── analysis_adapter.py # For the Adapter pattern\n",
    "    ├── analysis_composite.py # For the Composite pattern\n",
    "    └── analysis_strategy.py # For the Strategy pattern\n",
    "3. Implement Design Patterns\n",
    "3.1. Builder Pattern\n",
    "\n",
    "Create a builder class that constructs a data analysis pipeline.\n",
    "This class can have methods to add different analysis components and execute them.\n",
    "python\n",
    "Copy code\n",
    "# analysis/analysis_builder.py\n",
    "class DataAnalysisBuilder:\n",
    "    def __init__(self):\n",
    "        self.analyses = []\n",
    "\n",
    "    def add_analysis(self, analysis):\n",
    "        self.analyses.append(analysis)\n",
    "        return self\n",
    "\n",
    "    def execute(self, data):\n",
    "        results = {}\n",
    "        for analysis in self.analyses:\n",
    "            results[analysis.__class__.__name__] = analysis.perform_analysis(data)\n",
    "        return results\n",
    "3.2. Adapter Pattern\n",
    "\n",
    "Create adapter classes that enable the tool to handle different data formats (CSV, JSON).\n",
    "python\n",
    "Copy code\n",
    "# analysis/analysis_adapter.py\n",
    "import pandas as pd\n",
    "\n",
    "class DataAdapter:\n",
    "    def read_data(self, file_path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class CSVAdapter(DataAdapter):\n",
    "    def read_data(self, file_path):\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "class JSONAdapter(DataAdapter):\n",
    "    def read_data(self, file_path):\n",
    "        return pd.read_json(file_path)\n",
    "3.3. Composite Pattern\n",
    "\n",
    "Use the composite pattern to combine multiple analysis results.\n",
    "python\n",
    "Copy code\n",
    "# analysis/analysis_composite.py\n",
    "class AnalysisComponent:\n",
    "    def perform_analysis(self, data):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SummaryStatistics(AnalysisComponent):\n",
    "    def perform_analysis(self, data):\n",
    "        return data.describe()\n",
    "\n",
    "class Correlation(AnalysisComponent):\n",
    "    def perform_analysis(self, data):\n",
    "        return data.corr()\n",
    "3.4. Strategy Pattern\n",
    "\n",
    "Implement different strategies for analysis and visualization.\n",
    "python\n",
    "Copy code\n",
    "# analysis/analysis_strategy.py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class VisualizationStrategy:\n",
    "    def visualize(self, data):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BarChart(VisualizationStrategy):\n",
    "    def visualize(self, data):\n",
    "        data.plot(kind='bar')\n",
    "        plt.show()\n",
    "\n",
    "class ScatterPlot(VisualizationStrategy):\n",
    "    def visualize(self, data):\n",
    "        sns.scatterplot(x=data.columns[0], y=data.columns[1], data=data)\n",
    "        plt.show()\n",
    "4. Build the Flask Application\n",
    "Implement the Flask app in app.py, allowing users to upload files and view analysis results.\n",
    "python\n",
    "Copy code\n",
    "# app.py\n",
    "from flask import Flask, render_template, request, redirect\n",
    "from analysis.analysis_adapter import CSVAdapter, JSONAdapter\n",
    "from analysis.analysis_builder import DataAnalysisBuilder\n",
    "from analysis.analysis_composite import SummaryStatistics, Correlation\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def upload_page():\n",
    "    return render_template('upload.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    file = request.files['file']\n",
    "    file_format = file.filename.split('.')[-1]\n",
    "    \n",
    "    if file_format == 'csv':\n",
    "        adapter = CSVAdapter()\n",
    "    elif file_format == 'json':\n",
    "        adapter = JSONAdapter()\n",
    "    else:\n",
    "        return \"Unsupported file format\", 400\n",
    "\n",
    "    data = adapter.read_data(file)\n",
    "    builder = DataAnalysisBuilder()\n",
    "    builder.add_analysis(SummaryStatistics()).add_analysis(Correlation())\n",
    "    \n",
    "    results = builder.execute(data)\n",
    "    \n",
    "    return render_template('analysis.html', results=results)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "5. Create HTML Templates\n",
    "upload.html: Simple form for uploading datasets.\n",
    "html\n",
    "Copy code\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Upload Dataset</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Upload Dataset</h1>\n",
    "    <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
    "        <input type=\"file\" name=\"file\" required>\n",
    "        <button type=\"submit\">Upload</button>\n",
    "    </form>\n",
    "</body>\n",
    "</html>\n",
    "analysis.html: Display analysis results.\n",
    "html\n",
    "Copy code\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Analysis Results</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Analysis Results</h1>\n",
    "    <h2>Summary Statistics</h2>\n",
    "    <pre>{{ results['SummaryStatistics'].to_string() }}</pre>\n",
    "    <h2>Correlation</h2>\n",
    "    <pre>{{ results['Correlation'].to_string() }}</pre>\n",
    "    <a href=\"/\">Upload another dataset</a>\n",
    "</body>\n",
    "</html>\n",
    "6. Testing and Validation\n",
    "Test your application by uploading different datasets and verifying the output.\n",
    "Make sure to handle exceptions for invalid formats and empty datasets gracefully.\n",
    "7. Enhancements (Optional)\n",
    "Add more analysis and visualization strategies.\n",
    "Implement user authentication if required.\n",
    "Enhance the front-end with JavaScript and CSS for better user experience.\n",
    "Store uploaded datasets in a database for future reference.\n",
    "8. Documentation\n",
    "Document your code and design choices.\n",
    "Prepare a README file that explains how to run the application, its features, and how the design patterns are implemented.\n",
    "Conclusion\n",
    "This implementation plan should give you a clear path to developing your Data Analysis Tool. By using the specified design patterns, you'll not only create a functional application but also deepen your understanding of software design principles. If you have any questions or need further assistance, feel free to ask!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You said:\n",
    "now draw UML diagram for this project\n",
    "\n",
    "2/2\n",
    "\n",
    "ChatGPT said:\n",
    "ChatGPT\n",
    "Creating a UML diagram for your Data Analysis Tool project will help visualize the structure and relationships between the different classes and components. Below, I've outlined a UML class diagram that incorporates the design patterns we've discussed.\n",
    "\n",
    "UML Class Diagram\n",
    "plaintext\n",
    "Copy code\n",
    "+----------------------------------+\n",
    "|           DataAnalysisTool       |\n",
    "+----------------------------------+\n",
    "| - adapter: DataAdapter           |\n",
    "| - builder: DataAnalysisBuilder   |\n",
    "+----------------------------------+\n",
    "| + upload_file(file: File)        |\n",
    "| + display_results(results: dict) |\n",
    "+----------------------------------+\n",
    "\n",
    "          |          |\n",
    "          |          |\n",
    "          |          |\n",
    "          |          |\n",
    "+------------------+   +-------------------------+\n",
    "|   DataAdapter    |   |   DataAnalysisBuilder    |\n",
    "+------------------+   +-------------------------+\n",
    "| + read_data()    |   | - analyses: List[AnalysisComponent] |\n",
    "+------------------+   +-------------------------+\n",
    "|                  |   | + add_analysis(analysis: AnalysisComponent): self |\n",
    "|                  |   | + execute(data: DataFrame): dict |\n",
    "+------------------+   +-------------------------+\n",
    "|                  |  \n",
    "|                  |\n",
    "+------------------+\n",
    "          |\n",
    "          |--------+\n",
    "          |        |\n",
    "+-----------------+ +-----------------+\n",
    "|   CSVAdapter    | |  JSONAdapter    |\n",
    "+-----------------+ +-----------------+\n",
    "| + read_data()   | | + read_data()   |\n",
    "+-----------------+ +-----------------+\n",
    "\n",
    "          |\n",
    "          |\n",
    "          |          \n",
    "          |              \n",
    "+-----------------------------------+\n",
    "|          AnalysisComponent        |\n",
    "+-----------------------------------+\n",
    "| + perform_analysis(data: DataFrame) |\n",
    "+-----------------------------------+\n",
    "|                                   |\n",
    "|                                   |\n",
    "+-----------------------------------+\n",
    "|                                   |\n",
    "|                                   |\n",
    "+-----------------------------------+\n",
    "|                                   |\n",
    "|                                   |\n",
    "+-----------------------------------+\n",
    "          |            |\n",
    "          |            |\n",
    "+-----------------+ +----------------+\n",
    "|SummaryStatistics| |  Correlation    |\n",
    "+-----------------+ +----------------+\n",
    "| + perform_analysis() | + perform_analysis() |\n",
    "+-----------------+ +----------------+\n",
    "\n",
    "          |\n",
    "          |\n",
    "          |\n",
    "          |\n",
    "+----------------------------------+\n",
    "|      VisualizationStrategy       |\n",
    "+----------------------------------+\n",
    "| + visualize(data: DataFrame)     |\n",
    "+----------------------------------+\n",
    "|                                  |\n",
    "+----------------------------------+\n",
    "|                                  |\n",
    "+----------------------------------+\n",
    "          |           |\n",
    "          |           |\n",
    "+-------------------+ +-----------------+\n",
    "|      BarChart     | |   ScatterPlot   |\n",
    "+-------------------+ +-----------------+\n",
    "| + visualize()     | | + visualize()   |\n",
    "+-------------------+ +-----------------+\n",
    "Explanation of the UML Diagram\n",
    "Main Classes:\n",
    "\n",
    "DataAnalysisTool: This is the main class that controls the flow of the application. It has references to DataAdapter for reading data and DataAnalysisBuilder for executing analyses.\n",
    "DataAdapter Hierarchy:\n",
    "\n",
    "DataAdapter: An abstract class defining the method read_data().\n",
    "CSVAdapter and JSONAdapter: Concrete classes that implement read_data() for CSV and JSON files, respectively.\n",
    "Analysis Classes:\n",
    "\n",
    "DataAnalysisBuilder: This class manages a list of analysis components (AnalysisComponent). It allows adding new analyses and executing them.\n",
    "AnalysisComponent: An abstract class defining the method perform_analysis().\n",
    "SummaryStatistics and Correlation: Concrete classes that implement specific analyses.\n",
    "Visualization Strategy:\n",
    "\n",
    "VisualizationStrategy: An abstract class for visualizing data.\n",
    "BarChart and ScatterPlot: Concrete classes that implement specific visualization strategies.\n",
    "Relationships:\n",
    "Inheritance: The diagram shows the inheritance relationships between the base classes (DataAdapter, AnalysisComponent, and VisualizationStrategy) and their respective subclasses.\n",
    "Aggregation: The DataAnalysisBuilder class aggregates multiple AnalysisComponent instances, allowing for a flexible combination of analyses.\n",
    "Next Steps:\n",
    "Refinement: Based on your specific implementation details, you may want to refine the diagram (e.g., adding more specific methods or properties).\n",
    "Tool Usage: Use UML tools (like Lucidchart, Draw.io, or any UML software) to create a polished version of the diagram that you can include in your documentation.\n",
    "If you have further questions or need assistance with specific parts of your project, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szanowna Pani Doktor, \n",
    "chciałabym zgłosić temat projektu na przedmiot Wzorce Projektowe.\n",
    "Temat: Data Analysis Tool\n",
    "\n",
    "Opis: Narzędzie do analizy danych to aplikacja internetowa zaprojektowana, aby ułatwić użytkownikom eksplorację i wizualizację danych. Umożliwia ona przesyłanie zbiorów danych w różnych formatach, takich jak CSV i JSON, oraz przeprowadzanie podstawowych analiz, takich jak statystyki opisowe i obliczenia korelacji. Projekt będzie oparty na wzorcach projektowych, co zapewni elastyczność i modułowość aplikacji.  Aplikacja zostanie zbudowana w języku Python, przy użyciu biblioteki Pandas do manipulacji danymi oraz Matplotlib i Seaborn do wizualizacji.\n",
    "\n",
    "Z poważaniem,\n",
    "Alisa Malakhova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
